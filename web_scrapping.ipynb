{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXE4UL5ygMPmmbamzzaIVv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deepanshu2601/Deepanshumachinelearning/blob/main/web_scrapping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RQ7VB7x4PmFc"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://books.toscrape.com/catalogue/page-1.html\""
      ],
      "metadata": {
        "id": "qNdJ_5LNPpa6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "books = soup.find_all(\"article\", class_=\"product_pod\")\n",
        "\n",
        "for book in books:\n",
        "    title = book.h3.a[\"title\"]\n",
        "    print(title)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elXsaSYjPsXt",
        "outputId": "d08fa188-2f21-4150-938c-267168359603"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A Light in the Attic\n",
            "Tipping the Velvet\n",
            "Soumission\n",
            "Sharp Objects\n",
            "Sapiens: A Brief History of Humankind\n",
            "The Requiem Red\n",
            "The Dirty Little Secrets of Getting Your Dream Job\n",
            "The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull\n",
            "The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics\n",
            "The Black Maria\n",
            "Starving Hearts (Triangular Trade Trilogy, #1)\n",
            "Shakespeare's Sonnets\n",
            "Set Me Free\n",
            "Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\n",
            "Rip it Up and Start Again\n",
            "Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991\n",
            "Olio\n",
            "Mesaerion: The Best Science Fiction Stories 1800-1849\n",
            "Libertarianism for Beginners\n",
            "It's Only the Himalayas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "url = \"https://quotes.toscrape.com\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "# Extract quotes and authors\n",
        "quotes = [q.text for q in soup.find_all(\"span\", class_=\"text\")]\n",
        "authors = [a.text for a in soup.find_all(\"small\", class_=\"author\")]\n",
        "\n",
        "# Combine into list of tuples (for CSV)\n",
        "data = [(\"quote\", \"author\")]  # header row\n",
        "for q, a in zip(quotes, authors):\n",
        "    data.append((q, a))\n",
        "\n",
        "# Save to CSV\n",
        "with open(\"quotes.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(data)\n",
        "\n",
        "print(\"✅ Quotes saved to quotes.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKPjxvGTPu5s",
        "outputId": "fa74c9fd-5321-40eb-de6c-87d5692e5c25"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Quotes saved to quotes.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "base_url = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
        "\n",
        "books_data = [(\"Title\", \"Price\", \"Availability\", \"Star Rating\")]  # header row\n",
        "\n",
        "# Loop through all 50 pages\n",
        "for page in range(1, 51):\n",
        "    url = base_url.format(page)\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(f\"⚠️ Failed to fetch page {page}\")\n",
        "        continue\n",
        "\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    books = soup.find_all(\"article\", class_=\"product_pod\")\n",
        "\n",
        "    for book in books:\n",
        "        title = book.h3.a[\"title\"]\n",
        "        price = book.find(\"p\", class_=\"price_color\").text.strip()\n",
        "        availability = book.find(\"p\", class_=\"instock availability\").text.strip()\n",
        "        rating = book.find(\"p\", class_=\"star-rating\")[\"class\"][1]  # second class = One/Two/...\n",
        "\n",
        "        books_data.append((title, price, availability, rating))\n",
        "\n",
        "# Save to CSV\n",
        "with open(\"books.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(books_data)\n",
        "\n",
        "print(\"✅ Scraping completed! Data saved to books.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67ahRUZvP2dB",
        "outputId": "10d96771-bc4f-49fd-bd58-00b8a14c451d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Scraping completed! Data saved to books.csv\n"
          ]
        }
      ]
    }
  ]
}